{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Convert Pascal VOC Annotations to Desired Format.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BKI6EWp9Y6Z4"},"source":["# Installation in Jupyter Notebook\n","\n"," - Run these commands \n","     \n","     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n","     \n","     - cd Monk_Object_Detection/2_pytorch_finetune/installation\n","     \n"," - Select the right requirements file and run\n"," \n","     - cat requirements.txt | xargs -n 1 -L 1 pip install\n","\n","# Installation in Google Colab\n","\n"," - Run these commands \n","     \n","     - !git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n","     \n","     - %cd Monk_Object_Detection/2_pytorch_finetune/installation\n","     \n"," - Select the right requirements file and run\n"," \n","     - cat requirements.txt | xargs -n 1 -L 1 pip install"]},{"cell_type":"markdown","metadata":{"id":"I1-E8OOOY3Mu","colab_type":"text"},"source":["## Dataset Directory Structure - Required (to be fed in the model)\n","\n","    Parent_Directory (root)\n","          |\n","          |-----------Images (img_dir)\n","          |              |\n","          |              |------------------img1.jpg\n","          |              |------------------img2.jpg\n","          |              |------------------.........(and so on)\n","          |\n","          |\n","          |-----------train_labels.csv (anno_file)\n","          \n","          \n","## Annotation file format\n","\n","           | Id         | Labels                                 |\n","           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n","           \n","- Labels:  xmin ymin xmax ymax label\n","- x1, y1 - top left corner of bounding box\n","- x2, y2 - bottom right corner of bounding box"]},{"cell_type":"markdown","metadata":{"id":"LNuMxs4lY3M1","colab_type":"text"},"source":["# Sample Dataset Credits\n","\n","- credits: https://github.com/wujixiu/helmet-detection\n","- Dataset link (Pascal VOC 2007): https://pjreddie.com/projects/pascal-voc-dataset-mirror/"]},{"cell_type":"markdown","metadata":{"id":"wQzDB0OHcltn","colab_type":"text"},"source":["## Jupyter notebook\n","\n","- Run these commands \n","     \n","     - cd /root/dataset_Path\n","\n","## Google Colab\n","\n","- Run these commands \n","     \n","     - from google.colab import drive\n","     \n","     - drive.mount('/content/gdrive')\n","     - %cd /content/gdrive/My Drive/ (dataset_Path)"]},{"cell_type":"markdown","metadata":{"id":"9ofauPDAY3M3","colab_type":"text"},"source":["## Conversion\n","\n","We will read all the xml files in the Annotations folder and prepare a csv file which consists of image name and the label (as depicted above)."]},{"cell_type":"code","metadata":{"id":"NWpMvaQ9Y3NA","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","\n","import xmltodict\n","import json\n","from tqdm import tqdm\n","\n","from pycocotools.coco import COCO"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEfzly05Y3NE","colab_type":"code","colab":{}},"source":["root_dir = \"/content/gdrive/My Drive/\";\n","img_dir = \"JPEGImages/\";\n","anno_dir = \"Annotations/\";"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-OxckpyEY3NG","colab_type":"code","colab":{}},"source":["files = os.listdir(root_dir + anno_dir);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CrZ_04HY3NK","colab_type":"code","colab":{}},"source":["combined = [];\n","for i in tqdm(range(len(files))):\n","    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n","    f = open(annoFile, 'r');\n","    my_xml = f.read();\n","    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n","    fname = anno[\"filename\"];\n","    label_str = \"\";\n","    if(type(anno[\"object\"]) == list):\n","        for j in range(len(anno[\"object\"])):\n","            obj = dict(anno[\"object\"][j]);\n","            label = anno[\"object\"][j][\"name\"];\n","            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n","            x1 = bbox[\"xmin\"];\n","            y1 = bbox[\"ymin\"];\n","            x2 = bbox[\"xmax\"];\n","            y2 = bbox[\"ymax\"];\n","            if(j == len(anno[\"object\"])-1):\n","                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n","            else:        \n","                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n","    else:\n","        obj = dict(anno[\"object\"]);\n","        label = anno[\"object\"][\"name\"];\n","        bbox = dict(anno[\"object\"][\"bndbox\"])\n","        x1 = bbox[\"xmin\"];\n","        y1 = bbox[\"ymin\"];\n","        x2 = bbox[\"xmax\"];\n","        y2 = bbox[\"ymax\"];\n","        \n","        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n","    \n","    \n","    combined.append([fname, label_str])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_TqXozUY3NO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"a74c18f2-1bc6-4055-f1c5-20a1bcf1bc72","executionInfo":{"status":"ok","timestamp":1584716860259,"user_tz":-330,"elapsed":911,"user":{"displayName":"Sayan Chakraborty","photoUrl":"","userId":"00711099941263730797"}}},"source":["combined[:10]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['007958.jpg', '162 101 330 306 cat 1 1 499 373 sofa'],\n"," ['007964.jpg', '174 120 256 171 person 52 118 407 245 car'],\n"," ['007963.jpg',\n","  '285 291 304 337 person 263 293 284 335 person 457 230 500 248 car 1 322 80 375 car 1 338 38 375 car 1 200 470 334 train'],\n"," ['007954.jpg', '28 111 380 212 dog'],\n"," ['007959.jpg',\n","  '148 153 263 191 sofa 256 151 303 192 chair 121 166 176 196 chair 116 178 185 210 chair 102 191 212 275 chair 72 223 250 355 chair 46 268 274 500 chair'],\n"," ['007953.jpg',\n","  '312 167 327 214 person 258 192 284 217 person 220 193 240 220 person 193 176 213 220 person 105 171 126 221 person 125 178 143 223 person 86 174 104 226 person 68 168 89 226 person 41 175 57 228 person 28 174 43 236 person 3 192 15 241 person 12 195 27 227 person 264 215 319 298 person 155 250 190 290 person 196 365 282 392 person 95 210 136 270 person 121 210 151 249 person 51 237 92 292 person 70 259 115 339 person 144 355 208 395 bicycle 188 296 245 309 bicycle 76 299 107 366 bicycle 125 245 144 298 bicycle 95 247 128 303 bicycle 256 274 321 309 bicycle'],\n"," ['007970.jpg',\n","  '101 146 326 299 car 296 163 500 248 car 224 142 263 184 person'],\n"," ['007971.jpg', '1 1 500 333 car 179 83 323 261 person'],\n"," ['007997.jpg', '52 85 340 374 person 257 58 500 375 person'],\n"," ['007976.jpg',\n","  '204 129 228 151 aeroplane 232 154 254 177 aeroplane 266 185 288 207 aeroplane 265 206 288 228 aeroplane 272 229 294 249 aeroplane']]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"l4yrDHm3fHiM","colab_type":"text"},"source":["# Converting the list into a csv file of the desired format:\n","\n","The csv file is saved in the specified path. "]},{"cell_type":"code","metadata":{"id":"gWcpAfkPY3NR","colab_type":"code","colab":{}},"source":["df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n","df.to_csv(root_dir + \"/train_labels.csv\", index=False);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXVM2O_1Y3Ng","colab_type":"text"},"source":["# Author - Tessellate Imaging - https://www.tessellateimaging.com/\n","\n","# Monk Library - https://github.com/Tessellate-Imaging/monk_v1\n","\n","    Monk is an opensource low-code tool for computer vision and deep learning\n","\n","\n","## Monk features\n","   - low-code\n","   - unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n","   - syntax invariant wrapper\n","\n","## Enables\n","\n","    - to create, manage and version control deep learning experiments\n","    - to compare experiments across training metrics\n","    - to quickly find best hyper-parameters\n","\n","## At present it only supports transfer learning, but we are working each day to incorporate\n","\n","    - GUI based custom model creation\n","    - various object detection and segmentation algorithms\n","    - deployment pipelines to cloud and local platforms\n","    - acceleration libraries such as TensorRT\n","    - preprocessing and post processing libraries\n","\n","\n","## To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or dm us on linkedin\n","\n","    - Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n","    - Akash - https://www.linkedin.com/in/akashdeepsingh01/\n","\n"]},{"cell_type":"code","metadata":{"id":"c9xV8VzuY3Nh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}