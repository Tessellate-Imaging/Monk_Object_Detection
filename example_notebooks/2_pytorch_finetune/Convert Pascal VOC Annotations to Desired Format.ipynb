{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Convert Pascal VOC Annotations to Desired Format.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BKI6EWp9Y6Z4"},"source":["# Installation in Jupyter Notebook\n","\n"," - Run these commands \n","     \n","     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n","     \n","     - cd Monk_Object_Detection/2_pytorch_finetune/installation\n","     \n"," - Select the right requirements file and run\n"," \n","     - cat requirements.txt | xargs -n 1 -L 1 pip install\n","\n","# Installation in Google Colab\n","\n"," - Run these commands \n","     \n","     - !git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n","     \n","     - %cd Monk_Object_Detection/2_pytorch_finetune/installation\n","     \n"," - Select the right requirements file and run\n"," \n","     - cat requirements.txt | xargs -n 1 -L 1 pip install"]},{"cell_type":"markdown","metadata":{"id":"I1-E8OOOY3Mu","colab_type":"text"},"source":["## Dataset Directory Structure - Required (to be fed in the model)\n","\n","    Parent_Directory (root)\n","          |\n","          |-----------Images (img_dir)\n","          |              |\n","          |              |------------------img1.jpg\n","          |              |------------------img2.jpg\n","          |              |------------------.........(and so on)\n","          |\n","          |\n","          |-----------train_labels.csv (anno_file)\n","          \n","          \n","## Annotation file format\n","\n","           | Id         | Labels                                 |\n","           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n","           \n","- Labels:  xmin ymin xmax ymax label\n","- x1, y1 - top left corner of bounding box\n","- x2, y2 - bottom right corner of bounding box"]},{"cell_type":"markdown","metadata":{"id":"LNuMxs4lY3M1","colab_type":"text"},"source":["# Sample Dataset Credits\n","\n","- credits: https://github.com/wujixiu/helmet-detection\n","- Dataset link (Pascal VOC 2007): https://pjreddie.com/projects/pascal-voc-dataset-mirror/"]},{"cell_type":"markdown","metadata":{"id":"wQzDB0OHcltn","colab_type":"text"},"source":["## Jupyter notebook\n","\n","- Run these commands \n","     \n","     - cd /root/dataset_Path\n","\n","## Google Colab\n","\n","- Run these commands \n","     \n","     - from google.colab import drive\n","     \n","     - drive.mount('/content/gdrive')\n","     - %cd /content/gdrive/My Drive/ (dataset_Path)"]},{"cell_type":"markdown","metadata":{"id":"9ofauPDAY3M3","colab_type":"text"},"source":["## Conversion\n","\n","We will read all the xml files in the Annotations folder and prepare a csv file which consists of image name and the label (as depicted above)."]},{"cell_type":"code","metadata":{"id":"NWpMvaQ9Y3NA","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","\n","import xmltodict\n","import json\n","from tqdm import tqdm\n","\n","from pycocotools.coco import COCO"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEfzly05Y3NE","colab_type":"code","colab":{}},"source":["root_dir = \"../sample_dataset/\" # \"/content/gdrive/My Drive/\" - For those using google drive\n","img_dir = \"JPEGImages/\";\n","anno_dir = \"Annotations/\";"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-OxckpyEY3NG","colab_type":"code","colab":{}},"source":["files = os.listdir(root_dir + anno_dir);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CrZ_04HY3NK","colab_type":"code","colab":{}},"source":["combined = [];\n","for i in tqdm(range(len(files))):\n","    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n","    f = open(annoFile, 'r');\n","    my_xml = f.read();\n","    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n","    fname = anno[\"filename\"];\n","    label_str = \"\";\n","    if(type(anno[\"object\"]) == list):\n","        for j in range(len(anno[\"object\"])):\n","            obj = dict(anno[\"object\"][j]);\n","            label = anno[\"object\"][j][\"name\"];\n","            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n","            x1 = bbox[\"xmin\"];\n","            y1 = bbox[\"ymin\"];\n","            x2 = bbox[\"xmax\"];\n","            y2 = bbox[\"ymax\"];\n","            if(j == len(anno[\"object\"])-1):\n","                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n","            else:        \n","                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n","    else:\n","        obj = dict(anno[\"object\"]);\n","        label = anno[\"object\"][\"name\"];\n","        bbox = dict(anno[\"object\"][\"bndbox\"])\n","        x1 = bbox[\"xmin\"];\n","        y1 = bbox[\"ymin\"];\n","        x2 = bbox[\"xmax\"];\n","        y2 = bbox[\"ymax\"];\n","        \n","        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n","    \n","    \n","    combined.append([fname, label_str])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_TqXozUY3NO","colab_type":"code","colab":{}},"source":["combined[:100]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l4yrDHm3fHiM","colab_type":"text"},"source":["# Converting the list into a csv file of the desired format:\n","\n","The csv file is saved in the specified path. "]},{"cell_type":"code","metadata":{"id":"gWcpAfkPY3NR","colab_type":"code","colab":{}},"source":["df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n","df.to_csv(root_dir + \"/train_labels.csv\", index=False);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXVM2O_1Y3Ng","colab_type":"text"},"source":["# Author - Tessellate Imaging - https://www.tessellateimaging.com/\n","\n","# Monk Library - https://github.com/Tessellate-Imaging/monk_v1\n","\n","    Monk is an opensource low-code tool for computer vision and deep learning\n","\n","\n","## Monk features\n","   - low-code\n","   - unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n","   - syntax invariant wrapper\n","\n","## Enables\n","\n","    - to create, manage and version control deep learning experiments\n","    - to compare experiments across training metrics\n","    - to quickly find best hyper-parameters\n","\n","## At present it only supports transfer learning, but we are working each day to incorporate\n","\n","    - GUI based custom model creation\n","    - various object detection and segmentation algorithms\n","    - deployment pipelines to cloud and local platforms\n","    - acceleration libraries such as TensorRT\n","    - preprocessing and post processing libraries\n","\n","\n","## To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or dm us on linkedin\n","\n","    - Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n","    - Akash - https://www.linkedin.com/in/akashdeepsingh01/\n","\n"]},{"cell_type":"code","metadata":{"id":"c9xV8VzuY3Nh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}